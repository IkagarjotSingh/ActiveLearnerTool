#Read excel files generated by Gouri. (Placed the files in static/data folder as per flask hierarchy)
#make combinations of the requirements and provide cosine sim (Gouri's Code)
#add BinaryClass and MultiClass columns and provide random values
#save all the data back to static/data folder

import warnings
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from string import punctuation
import numpy as np
import random
import pandas as pd
import os
import argparse
import xlrd

pd.set_option('display.max_columns', 500)   #To make sure all the columns are visible in the logs.
pd.set_option('display.width', 1000)

def get_args():
    parser = argparse.ArgumentParser(description="This script makes combinations of the requirements, cleans-up"
    "noisy data and creates a database for machine learning model.", formatter_class = argparse.ArgumentDefaultsHelpFormatter)
     
    parser.add_argument("--input","-i",type=str,required = True, help="path to raw requirement data file")
    parser.add_argument("--output","-o",type=str,required=True,help="path to save the requirement combinations file")
    parser.add_argument("--prep_needed","-pd",type=str,default='n', required=False,help="The BinaryClass and MultiClass labels need to be updated Randomly. y/n")
    args = parser.parse_args()
    return args


def cosineSim(req1,req2):
    req1 = req1.replace("\n","")
    req2 = req2.replace("\n","")
    
    documents=(req1,req2)

    tfidf_vectorizer=TfidfVectorizer()
    tfidf_matrix=tfidf_vectorizer.fit_transform(documents)
    #print tfidf_matrix.shape
    cs=cosine_similarity(tfidf_matrix[0:1],tfidf_matrix)
    #print (documents, cs)
    return cs[0][1]

def cleanUp(String):
    String = String.strip()
    String = String.strip(punctuation)
    String = String.replace(r"@\S+", "")
    String = String.replace(r"[^A-Za-z0-9(),!?@\'\`\"\_\n\r\t]", "")
    String = String.replace(r"@", "at")
    String = String.replace(r".", "")
    String = String.replace(r"'", "")
    String = String.replace(r",", "")
    String = String.lower()
    return String

def addRandomClassValues(df):
    '''
    Add new columns BinaryClass and MultiClass with random values
    
    Binary Class
     0 - Independent
     1 - Dependent

    Multi Class
     0 - Independent
     1 - AND
     2 - OR
     3 - Requires
     4 - Similar
     5 - Cannot Say
    '''
    df['BinaryClass'] = np.random.randint(0, 2, df.shape[0])  #add random values for Binary Class
    for i,row in df.iterrows():
        if row['BinaryClass']==1:
            df.at[i,'MultiClass']=np.random.randint(1, 6)
    return df

def detectClones(df_req):
    
    count = 0
    df_SimReq1Req2 = pd.DataFrame(columns={'req1', 'req1_id', 'req2', 'req2_id', 'similarity', 'cosine'})
    for i_index, i_row in df_req.iterrows():
        req1 = cleanUp(str(i_row['Description'])) 
        req1_Id = str(i_row['RQ']).strip() #Update the column name as mentioned by Brandon in the file
        count = count + 1
        #for j_index, j_row in df_req.iterrows(): for i, r in df.iloc[1:].iterrows():
        #https://stackoverflow.com/questions/38596056/how-to-change-the-starting-index-of-iterrows
        # this is to make sure no duplicate cobinations are captured: as a to b is same as b to a
        
        for j_index, j_row in df_req.iloc[i_index+1:].iterrows(): 
            req2 = cleanUp(str(j_row['Description']))
            req2_Id = str(j_row['RQ']).strip()
           
            similarityIs = 0 #Simtool(req1, req2)
            cosineSimilarity = cosineSim(req1, req2)
            df_SimReq1Req2 = df_SimReq1Req2.append({'req1':req1, 'req1_id':req1_Id, 'req2':req2, 'req2_id':req2_Id, 'similarity':similarityIs, 'cosine':cosineSimilarity}, ignore_index=True)
           
    return df_SimReq1Req2

def main():

    warnings.simplefilter(action='ignore', category=FutureWarning)
    args=get_args()
    dirPath = os.getcwd()+"/static/data/" #os.getcwd() returns the current working directory path
    #ifileName = 'raw-data/blackLine-RandDDoc - RQs-comments removed - may27.csv'  #file generated by Brandon
    #ofileName = #'blackLine-combined.csv'  #final output file, which will be displayed in Intelligent Annotator
    
    ifileName = args.input
    ofileName = args.output
    preprocessingNeeded = args.prep_needed
    
    print ("Processing...")
    data = pd.read_csv(dirPath+ifileName)
    rqmt_combinations = detectClones(data)
    if preprocessingNeeded =='y':
        rqmt_combinations = addRandomClassValues(rqmt_combinations)    #No need to add random values 
    
    #save data to csv file
    rqmt_combinations.to_csv(dirPath+ofileName, sep=',', index = False, encoding='utf-8', columns=['req1', 'req1_id', 'req2', 'req2_id', 'similarity', 'cosine','BinaryClass','MultiClass','BLabelled','MLabelled'])  #updated index = False, so that index values are not saved in csv, as everytime we read the file, index values will be generated by default.
    print ("Preprocessing Completed....")
    print ("Ouput file saved at : ",dirPath+ofileName)

if __name__ == '__main__':
    main()